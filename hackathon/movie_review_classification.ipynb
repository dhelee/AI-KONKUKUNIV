{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hackathon.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uIRox-dwrkE"
      },
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import sys\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYyvvcCHZ5oq"
      },
      "source": [
        "## 1. 데이터 불러오기 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tYyEYFNwCNK"
      },
      "source": [
        "# 학습 데이터를 불러와서 id, document, label 리스트를 반환\n",
        "def read_train_data(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf8\") as inFile:\n",
        "        lines = inFile.readlines()\n",
        "\n",
        "    ids, docs, labels = [], [], []\n",
        "    for index, line in enumerate(tqdm(lines, desc=\"read_data\")):\n",
        "        pieces = line.strip().split(\"\\t\")\n",
        "        # 데이터의 형태가 올바른지 체크\n",
        "        assert len(pieces) == 3\n",
        "        if(index == 0):\n",
        "            continue\n",
        "        id, doc, label = pieces[0], pieces[1], int(pieces[2])\n",
        "        ids.append(id)\n",
        "        docs.append(doc)\n",
        "        labels.append(label)\n",
        "\n",
        "    return ids, docs, labels\n",
        "\n",
        "\n",
        "# 평가 데이터를 불러와서 id, document 리스트를 반환\n",
        "def read_test_data(file_path):\n",
        "  with open(file_path, \"r\", encoding=\"utf8\") as inFile:\n",
        "        lines = inFile.readlines()\n",
        "\n",
        "  ids, docs = [], [] \n",
        "  for index, line in enumerate(tqdm(lines, desc=\"read_data\")):\n",
        "      pieces = line.strip().split(\"\\t\")\n",
        "      # 데이터의 형태가 올바른지 체크\n",
        "      assert len(pieces) == 2\n",
        "      if(index == 0):\n",
        "          continue\n",
        "      id, doc = pieces[0], pieces[1]\n",
        "      ids.append(id)\n",
        "      docs.append(doc)\n",
        "\n",
        "  return ids, docs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymFpM8DezNh5"
      },
      "source": [
        "root_dir = \"drive/My Drive/Hackathon/\"\n",
        "\n",
        "train_dir = os.path.join(root_dir, \"ratings_train.txt\")\n",
        "test_dir = os.path.join(root_dir, \"ratings_test.txt\")\n",
        "\n",
        "train_id, train_doc, train_label = read_train_data(file_path=train_dir)\n",
        "test_id, test_doc, test_label = read_train_data(file_path=test_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFU6fIauaDQ_"
      },
      "source": [
        "## 2. 리뷰 데이터 형태소 분석 및 품사 태깅 \n",
        "#### 1) konlpy 패키지의 Okt 클래스 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFhV49WXWtNG"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VA5k3n_Wehq"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "okt = Okt()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lv5J-PMtl3m-"
      },
      "source": [
        "#### 2) 각 리뷰를 '형태소/품사' 형태로 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YFP7JMmW4J1"
      },
      "source": [
        "def tokenize(doc):\n",
        "    return ['/'.join(t) for t in okt.pos(doc, norm=True, stem=True)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E-RqqO0lSCR"
      },
      "source": [
        "tokenize(train_doc[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkvJpe0GlZSf"
      },
      "source": [
        "train_doc_tkn = [(tokenize(x)) for x in train_doc]\n",
        "test_doc_tkn = [(tokenize(x)) for x in test_doc]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNNIlDv8NaPp"
      },
      "source": [
        "# tokenize된 총 20만개의 학습 데이터셋\n",
        "total_docs = np.concatenate((train_doc_tkn, test_doc_tkn), axis = 0)\n",
        "total_labels = np.concatenate((train_label, test_label), axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xv9uzGxGaLzf"
      },
      "source": [
        "## 3. 모델 1 - CountVectorizer + TfidfTransformer + SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iQ85bLnA5td"
      },
      "source": [
        "# countvectorizer의 input 형태로 전환 \n",
        "train_docs = []\n",
        "\n",
        "for i in range(len(total_docs)):\n",
        "  seq = \"\"\n",
        "  for j in range(len(total_docs[i])):\n",
        "    seq = seq + total_docs[i][j] + \" \"\n",
        "  train_docs.append(seq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PwmhdGumJoP"
      },
      "source": [
        "#### 1) CountVectorizer를 이용하여 각 리뷰를 벡터화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1kw83mOuNQK"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "feature_train_X = vectorizer.fit_transform(train_docs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_Ns8zhtmVXI"
      },
      "source": [
        "#### 2) TfidfTransformer를 이용하여 각 토큰의 tf-idf값으로 벡터를 transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYv0D3aiilGN"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "transformer = TfidfTransformer(smooth_idf = True)\n",
        "trans_train_X = transformer.fit_transform(feature_train_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iXCftTWmpJ5"
      },
      "source": [
        "#### 3) Support Vector Machine으로 학습\n",
        "- 각 모델의 validation accuracy 비교\n",
        "\n",
        "| Validation Accuracy | KNN | DT | MEM | NB | SVM | \n",
        "| --- | --- | --- | --- | --- | --- |\n",
        "| | 76% | 75% | 83% | 83% | 85% |\n",
        "\n",
        "- hyper-parameter tuning  \n",
        "C=1.62, kernel='rbf'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi6CSDZD3_Zf"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "model_1 = SVC(C=1.62, kernel='rbf')\n",
        "model_1.fit(trans_train_X, total_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ7bC0HJBlz2"
      },
      "source": [
        "from sklearn.externals import joblib \n",
        "\n",
        "# 실제 테스트 상황에서 사용하기 위해 모델 저장 \n",
        "joblib.dump(model_1, os.path.join(root_dir, \"model_1.pkl\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg2bCKhFaidk"
      },
      "source": [
        "## 4. 모델 2 - Word2vec + SVM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN5boKxmpH1F"
      },
      "source": [
        "#### 1) gensim 패키지의 Word2Vec 이용하여 각 단어의 벡터값 계산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rop7UuLQLLuA"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "w2v_model = Word2Vec(sentences=total_docs, size = 300, window=5, min_count=1, workers=4, sg=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkoR5oNyLLnA"
      },
      "source": [
        "# 실제 테스트 상황에서 사용하기 위해 모델 저장 \n",
        "w2v_model.save(os.path.join(root_dir, \"w2v_model.model\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi9zXLIKpat4"
      },
      "source": [
        "#### 2) 각 리뷰를 단어들의 벡터값으로 표현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoOhNB0_LLiT"
      },
      "source": [
        "# total_docs에는 tokenize된 데이터가, w2v_train_X에는 벡터화된 데이터가 들어감\n",
        "# gensim의 wv.get_vector를 이용해 total_docs의 각 단어 벡터를 받아와 w2v_train_X에 저장\n",
        "\n",
        "temp_lst, w2v_train_X = [], []\n",
        "\n",
        "for i in range(len(total_docs)):\n",
        "  temp_lst = []\n",
        "  for j in range(len(total_docs[i])):\n",
        "    temp_lst.append(w2v_model.wv.get_vector(total_docs[i][j]))\n",
        "  w2v_train_X.append(temp_lst)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS5rj7GypvlT"
      },
      "source": [
        "#### 3) 열별 평균을 내어 각 리뷰 벡터를 300X1 벡터로 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h4p5MdMMDmK"
      },
      "source": [
        "# w2v_train_X에는 행은 300, 열은 문장 내 단어 개수인 행렬이 20만개 들어가 있음\n",
        "# 예를 들어 첫번째 문장의 단어수가 11개면 첫번째 행렬은 300x11\n",
        "# 전처리 과정에서 단어 수가 0개인 문장이 생길 수 있음\n",
        "\n",
        "#각 열별로 평균을 낸 300x1의 벡터를 구하여 total_X_lst에 저장\n",
        "# total_X_lst에는 20만개의 문장 벡터가 들어감\n",
        "\n",
        "total_X_lst, total_empty_lst, total_Y_lst = [], [], []\n",
        "\n",
        "for i in range(len(w2v_train_X)):\n",
        "  # 비어있는 array의 평균을 구할 때 뜨는 에러는 try-except문으로 처리\n",
        "  try:\n",
        "    temp = list(np.array(w2v_train_X[i]).mean(axis= 0))\n",
        "    total_X_lst.append(temp)\n",
        "    total_Y_lst.append(total_labels[i])\n",
        "  except:\n",
        "    total_empty_lst.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr8suZOaqN7U"
      },
      "source": [
        "#### 4) Support Vector Machine학습\n",
        "- Standard Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiOwHRnMMD0N"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# standard scaling\n",
        "model_2 = Pipeline([\n",
        "            (\"scaler\", StandardScaler()),\n",
        "            (\"svm_clf\", SVC(kernel = \"rbf\", C=1.62))])\n",
        "model_2.fit(total_X_lst, total_Y_lst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve4MK-s1MDvk"
      },
      "source": [
        "# 실제 테스트 상황에서 사용하기 위해 모델 저장 \n",
        "joblib.dump(model_2, os.path.join(root_dir, \"model_2.pkl\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khwEBy2uauKB"
      },
      "source": [
        "## 5. 평가 데이터 예측"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLlK7-OPq-c1"
      },
      "source": [
        "#### 1) 평가 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y8Q5E3MMDtm"
      },
      "source": [
        "test_id, test_doc = read_test_data(file_path=os.path.join(root_dir, \"ratings_eval.txt\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKPeZ7OirBZe"
      },
      "source": [
        "#### 2) 평가 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0jLVCdegiWE"
      },
      "source": [
        "test_doc_tkn = [(tokenize(x)) for x in test_doc]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLg85ZS-rIS0"
      },
      "source": [
        "#### 3) 모델 1 prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozhI5mn8MDpA"
      },
      "source": [
        "feature_test_X = vectorizer.transform(test_doc_tkn)\n",
        "trans_test_X = transformer.fit_transform(feature_test_X)\n",
        "\n",
        "md1_pred = model_1.predict(trans_tes_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36u37ghWrNR6"
      },
      "source": [
        "#### 4) 모델 2 prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KFX4iDSWjGw"
      },
      "source": [
        "temp_lst, test_word2vec_lst = [], []\n",
        "\n",
        "for i in range(len(test_X)):\n",
        "  temp_lst = []\n",
        "  for j in range(len(test_X[i])):\n",
        "    try:\n",
        "      temp_lst.append(w2v_model.wv.get_vector(test_X[i][j]))\n",
        "    except:\n",
        "      pass\n",
        "  test_word2vec_lst.append(temp_lst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MMucAW5XXvY"
      },
      "source": [
        "test_X_lst, test_empty_lst, test_id_lst = [], [], []\n",
        "\n",
        "for i in range(len(test_word2vec_lst)):\n",
        "  # 비어있는 array의 평균을 구할 때 뜨는 에러 처리\n",
        "  try:\n",
        "    temp = list(np.array(test_word2vec_lst[i]).mean(axis= 0))\n",
        "    test_X_lst.append(temp)\n",
        "    test_id_lst.append(test_id[i])\n",
        "  except:\n",
        "    # 모델 2로 예측할 수 없는 리뷰의 index를 저장 \n",
        "    test_empty_lst.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVDTCISLXflU"
      },
      "source": [
        "md2_pred = model_2.predict(test_X_lst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcvGIiqzYHBM"
      },
      "source": [
        "id_pred_lst = []\n",
        "for i in range(len(test_id_lst)):\n",
        "  id_pred_lst.append([test_id_lst[i], md2_pred[i]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ckwtzdFYHKY"
      },
      "source": [
        "# 모델 2가 예측하지 못하는 리뷰의 라벨은 0.5로 채움\n",
        "for i in test_empty_lst:\n",
        "  id_pred_lst = id_pred_lst[:i] + [[test_id[i], 0.5]] + id_pred_lst[i:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50a9cuwSa13S"
      },
      "source": [
        "## 6. 앙상블"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDlMqB8OsY2U"
      },
      "source": [
        "- 모델 1과 모델 2의 예측값에 각각 0.9, 1.1의 가중치를 두어 최종 예측값 산출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn8zJ8lckPHV"
      },
      "source": [
        "ensemble_pred = []\n",
        "\n",
        "for i in range(len(md1_pred)):\n",
        "  md1_v = float(md1_pred[i]) * 0.9\n",
        "  md2_v = float(id_pred_lst[i][1]) * 1.1\n",
        "  pred = (md1_v + md2_v) / 2\n",
        "\n",
        "  if pred > 0.5:\n",
        "    ensemble_pred.append((id_pred_lst[i][0], 1))\n",
        "  else:\n",
        "    ensemble_pred.append((id_pred_lst[i][0], 0))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}